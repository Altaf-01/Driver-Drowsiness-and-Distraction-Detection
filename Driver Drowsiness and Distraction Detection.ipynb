{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "labels = os.listdir(r\"archive/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize A random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(plt.imread(r\"archive/train/Closed/_0.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plt.imread(r\"archive/train/yawn/10.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize yawn image(Background is unnecessary. We need only face image array) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread(r\"archive/train/yawn/10.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take only face(For yawn and not_yawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_for_yawn(direc=r\"archive/train\", face_cas_path=r\"haarcascade_frontalface_default.xml\"):#archive(1)\\haarcascade_frontalface_default.xml\n",
    "    yaw_no = []\n",
    "    IMG_SIZE = 145\n",
    "    categories = [\"yawn\", \"no_yawn\"]\n",
    "    for category in categories:\n",
    "        path_link = os.path.join(direc, category)\n",
    "        class_num1 = categories.index(category)\n",
    "        print(class_num1)\n",
    "        for image in os.listdir(path_link):\n",
    "            image_array = cv2.imread(os.path.join(path_link, image), cv2.IMREAD_COLOR)\n",
    "            face_cascade = cv2.CascadeClassifier(face_cas_path)\n",
    "            faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n",
    "            for (x, y, w, h) in faces:\n",
    "                img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                roi_color = img[y:y+h, x:x+w]\n",
    "                resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "                yaw_no.append([resized_array, class_num1])\n",
    "    return yaw_no\n",
    "\n",
    "\n",
    "yawn_no_yawn = face_for_yawn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Closed and Open eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_path=r\"archive/train\", face_cas=r\"haarcascade_frontalface_default.xml\", eye_cas=r\"haarcascade.xml\"):#archive(1)\\haarcascade_frontalface_default.xml\", eye_cas=r\"archive(1)\\haarcascade.xml\n",
    "    labels = ['Closed', 'Open']\n",
    "    IMG_SIZE = 145\n",
    "    data = []\n",
    "    for label in labels:\n",
    "        path = os.path.join(dir_path, label)\n",
    "        class_num = labels.index(label)\n",
    "        class_num +=2\n",
    "        print(class_num)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([resized_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend data and Convert array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    #total_data = []\n",
    "    yaw_no = face_for_yawn()\n",
    "    data = get_data()\n",
    "    yaw_no.extend(data)\n",
    "    #print(yaw_no)\n",
    "    return (yaw_no)#np.array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New variable to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = append_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate label and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for feature, label in new_data:\n",
    "    X.append(feature)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.reshape(-1, 145, 145, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_bin = LabelBinarizer()\n",
    "y = label_bin.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 42\n",
    "test_size = 0.30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\n",
    "test_generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "#train_generator = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "#test_generator = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "train_generator = train_generator.flow(np.array(X_train), y_train, shuffle=False)\n",
    "test_generator = test_generator.flow(np.array(X_test), y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=(145,145,3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=5, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, \"b\", label=\"trainning accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, \"b\", label=\"trainning loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"drowiness_new7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"drowiness_new7.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = (model.predict(X) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import classification_report\n",
    "#print(classification_report(np.argmax(y_test, axis=1), prediction, target_names=labels_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = [\"yawn\", \"no_yawn\", \"Closed\", \"Open\"]\n",
    "IMG_SIZE = 145\n",
    "def prepare(filepath, face_cas=r\"haarcascade_frontalface_default.xml\"):\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "    img_array = img_array / 255\n",
    "    resized_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return resized_array.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "model = tf.keras.models.load_model(\"drowiness_new7.h5\")#E:\\drowsy eye\\driver_drowsiness_system_CNN-main\\drowiness_new7.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction \n",
    "## 0-yawn, 1-no_yawn, 2-Closed, 3-Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare(\"../input/drowsiness-dataset/train/no_yawn/1068.jpg\")\n",
    "prediction = model.predict([prepare(r\"archive/train/no_yawn/1067.jpg\")])\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare(r\"archive/train/Closed/_101.jpg\")])\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare(r\"archive/train/Closed/_104.jpg\")])\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict([prepare(r\"archive/train/yawn/12.jpg\")])\n",
    "np.argmax(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "#from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from playsound import playsound\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "def start_alarm(sound):#sound\n",
    "    \"\"\"Play the alarm sound\"\"\"\n",
    "    playsound(sound)\n",
    "\n",
    "\n",
    "classes = ['Closed', 'Open']\n",
    "face_cascade = cv2.CascadeClassifier(r\"E:\\projects\\driver_drowsiness_system_CNN-main\\haarcascade_frontalface_default.xml\")\n",
    "left_eye_cascade = cv2.CascadeClassifier(r\"E:\\projects\\driver_drowsiness_system_CNN-main\\haarcascade_lefteye_2splits.xml\")\n",
    "right_eye_cascade = cv2.CascadeClassifier(r\"E:\\projects\\driver_drowsiness_system_CNN-main\\haarcascade_righteye_2splits.xml\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "model = load_model(r\"E:\\projects\\driver_drowsiness_system_CNN-main\\drowiness_new7.h5\")\n",
    "count = 0\n",
    "alarm_on = False\n",
    "alarm_sound = \"E:\\projects\\driver_drowsiness_system_CNN-main\\malarm.wav\"\n",
    "status1 = ''\n",
    "status2 = ''\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    height = frame.shape[0]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 1)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        left_eye = left_eye_cascade.detectMultiScale(roi_gray)\n",
    "        right_eye = right_eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (x1, y1, w1, h1) in left_eye:\n",
    "            cv2.rectangle(roi_color, (x1, y1), (x1 + w1, y1 + h1), (0, 255, 0), 1)\n",
    "            eye1 = roi_color[y1:y1+h1, x1:x1+w1]\n",
    "            eye1 = cv2.resize(eye1, (145, 145))\n",
    "            eye1 = eye1.astype('float') / 255.0\n",
    "            eye1 = img_to_array(eye1)\n",
    "            eye1 = np.expand_dims(eye1, axis=0)\n",
    "            pred1 = model.predict(eye1)\n",
    "            status1=np.argmax(pred1)\n",
    "            #print(status1)\n",
    "            #status1 = classes[pred1.argmax(axis=-1)[0]]\n",
    "            break\n",
    "\n",
    "        for (x2, y2, w2, h2) in right_eye:\n",
    "            cv2.rectangle(roi_color, (x2, y2), (x2 + w2, y2 + h2), (0, 255, 0), 1)\n",
    "            eye2 = roi_color[y2:y2 + h2, x2:x2 + w2]\n",
    "            eye2 = cv2.resize(eye2, (145, 145))\n",
    "            eye2 = eye2.astype('float') / 255.0\n",
    "            eye2 = img_to_array(eye2)\n",
    "            eye2 = np.expand_dims(eye2, axis=0)\n",
    "            pred2 = model.predict(eye2)\n",
    "            status2=np.argmax(pred2)\n",
    "            #print(status2)\n",
    "            #status2 = classes[pred2.argmax(axis=-1)[0]]\n",
    "            break\n",
    "\n",
    "        # If the eyes are closed, start counting\n",
    "        if status1 == 2 and status2 == 2:\n",
    "        #if pred1 == 2 and pred2 == 2:\n",
    "            count += 1\n",
    "            cv2.putText(frame, \"Eyes Closed, Frame count: \" + str(count), (10, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1)\n",
    "            # if eyes are closed for 10 consecutive frames, start the alarm\n",
    "            \n",
    "            if count >= 10:\n",
    "                cv2.putText(frame, \"Drowsiness Alert!!!\", (100, height-20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "                if not alarm_on:\n",
    "                    alarm_on = True\n",
    "                    # play the alarm sound in a new thread\n",
    "                    t = Thread(target=start_alarm, args=(alarm_sound,))\n",
    "                    t.daemon = True\n",
    "                    t.start()\n",
    "\n",
    "        else:\n",
    "            cv2.putText(frame, \"Eyes Open\", (10, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 1)\n",
    "            count = 0\n",
    "            alarm_on = False\n",
    "\n",
    "    cv2.imshow(\"Drowsiness Detector\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87b7bd39d341b484c5b823b7dfeada6cb173fab7ae76cbb00bb1f6ffc967dc38"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
